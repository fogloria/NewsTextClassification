{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: torch in /Users/admin/anaconda3/lib/python3.7/site-packages (1.5.1)\n",
      "Requirement already satisfied: torchvision in /Users/admin/anaconda3/lib/python3.7/site-packages (0.6.1)\n",
      "Requirement already satisfied: numpy in /Users/admin/anaconda3/lib/python3.7/site-packages (from torch) (1.18.1)\n",
      "Requirement already satisfied: future in /Users/admin/anaconda3/lib/python3.7/site-packages (from torch) (0.18.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Users/admin/anaconda3/lib/python3.7/site-packages (from torchvision) (7.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11e9a6f50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)-15s %(levelname)s: %(message)s')\n",
    "\n",
    "# set seed\n",
    "seed = 666\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-27 16:48:09,368 INFO: Fold lens [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000]\n"
     ]
    }
   ],
   "source": [
    "# split data to 10 fold\n",
    "fold_num = 10\n",
    "data_file = '../input/train_set.csv'\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def all_data2fold(fold_num, num=10000):\n",
    "    fold_data = []\n",
    "    \n",
    "    # 读取数据文件\n",
    "    f = pd.read_csv(data_file, sep='\\t', encoding='UTF-8')\n",
    "    \n",
    "    # 读取到num到的数据到text\n",
    "    texts = f['text'].tolist()[:num]\n",
    "    \n",
    "    # 读取到num到的数据到label\n",
    "    labels = f['label'].tolist()[:num]\n",
    "    \n",
    "    # 获取标签数\n",
    "    total = len(labels)\n",
    "\n",
    "    # 使用标签数，生成列表\n",
    "    index = list(range(total))\n",
    "    \n",
    "    # 打乱顺序\n",
    "    np.random.shuffle(index)\n",
    "\n",
    "    # 定义所有text\n",
    "    all_texts = []\n",
    "    # 定义所有label\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in index:\n",
    "        # 把打乱顺序的text，放进所有text\n",
    "        all_texts.append(texts[i])\n",
    "        \n",
    "        # 把打乱顺序的label，放进所有label\n",
    "        all_labels.append(labels[i])\n",
    "\n",
    "    label2id = {}\n",
    "    \n",
    "    #给每个label赋予索引值\n",
    "    for i in range(total):\n",
    "        \n",
    "        # 按索引顺序 ，从打乱顺序的所有label例取出label\n",
    "        label = str(all_labels[i])\n",
    "        \n",
    "        # 如果 label不在label2id里的话：\n",
    "        if label not in label2id:\n",
    "            # 给这个label更新索引值\n",
    "            label2id[label] = [i]\n",
    "        else:\n",
    "            # 给这个label追加索引值\n",
    "            label2id[label].append(i)\n",
    "    \n",
    "    # 定义fold_num个列表\n",
    "    all_index = [[] for _ in range(fold_num)]\n",
    "    \n",
    "    # 遍历label2id里每个label和data\n",
    "    for label, data in label2id.items():\n",
    "        # print(label, len(data))\n",
    "        \n",
    "        # data和fold_num来确定批量尺寸\n",
    "        batch_size = int(len(data) / fold_num)\n",
    "        \n",
    "        # \n",
    "        other = len(data) - batch_size * fold_num\n",
    "        for i in range(fold_num):\n",
    "            cur_batch_size = batch_size + 1 if i < other else batch_size\n",
    "            # print(cur_batch_size)\n",
    "            batch_data = [data[i * batch_size + b] for b in range(cur_batch_size)]\n",
    "            all_index[i].extend(batch_data)\n",
    "\n",
    "    batch_size = int(total / fold_num)\n",
    "    other_texts = []\n",
    "    other_labels = []\n",
    "    other_num = 0\n",
    "    start = 0\n",
    "    for fold in range(fold_num):\n",
    "        num = len(all_index[fold])\n",
    "        texts = [all_texts[i] for i in all_index[fold]]\n",
    "        labels = [all_labels[i] for i in all_index[fold]]\n",
    "\n",
    "        if num > batch_size:\n",
    "            fold_texts = texts[:batch_size]\n",
    "            other_texts.extend(texts[batch_size:])\n",
    "            fold_labels = labels[:batch_size]\n",
    "            other_labels.extend(labels[batch_size:])\n",
    "            other_num += num - batch_size\n",
    "        elif num < batch_size:\n",
    "            end = start + batch_size - num\n",
    "            fold_texts = texts + other_texts[start: end]\n",
    "            fold_labels = labels + other_labels[start: end]\n",
    "            start = end\n",
    "        else:\n",
    "            fold_texts = texts\n",
    "            fold_labels = labels\n",
    "\n",
    "        assert batch_size == len(fold_labels)\n",
    "\n",
    "        # shuffle\n",
    "        index = list(range(batch_size))\n",
    "        np.random.shuffle(index)\n",
    "\n",
    "        shuffle_fold_texts = []\n",
    "        shuffle_fold_labels = []\n",
    "        for i in index:\n",
    "            shuffle_fold_texts.append(fold_texts[i])\n",
    "            shuffle_fold_labels.append(fold_labels[i])\n",
    "\n",
    "        data = {'label': shuffle_fold_labels, 'text': shuffle_fold_texts}\n",
    "        fold_data.append(data)\n",
    "\n",
    "    logging.info(\"Fold lens %s\", str([len(data['label']) for data in fold_data]))\n",
    "\n",
    "    return fold_data\n",
    "\n",
    "\n",
    "fold_data = all_data2fold(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-27 16:48:20,829 INFO: Total 9000 docs.\n"
     ]
    }
   ],
   "source": [
    "# build train data for word2vec\n",
    "fold_id = 9\n",
    "\n",
    "train_texts = []\n",
    "for i in range(0, fold_id):\n",
    "    data = fold_data[i]\n",
    "    train_texts.extend(data['text'])\n",
    "    \n",
    "logging.info('Total %d docs.' % len(train_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already up-to-date: gensim in /Users/admin/anaconda3/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /Users/admin/anaconda3/lib/python3.7/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /Users/admin/anaconda3/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /Users/admin/anaconda3/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /Users/admin/anaconda3/lib/python3.7/site-packages (from gensim) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /Users/admin/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: boto in /Users/admin/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in /Users/admin/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.14.28)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/admin/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/admin/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /Users/admin/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /Users/admin/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.18.0,>=1.17.28 in /Users/admin/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.28)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /Users/admin/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /Users/admin/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /Users/admin/anaconda3/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.28->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /Users/admin/anaconda3/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.28->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-27 16:56:54,722 INFO: Start training...\n",
      "2020-07-27 16:56:55,965 INFO: collecting all words and their counts\n",
      "2020-07-27 16:56:55,966 INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-07-27 16:56:57,575 INFO: collected 5267 word types from a corpus of 8162291 raw words and 9000 sentences\n",
      "2020-07-27 16:56:57,576 INFO: Loading a fresh vocabulary\n",
      "2020-07-27 16:56:57,628 INFO: effective_min_count=5 retains 4334 unique words (82% of original 5267, drops 933)\n",
      "2020-07-27 16:56:57,628 INFO: effective_min_count=5 leaves 8160401 word corpus (99% of original 8162291, drops 1890)\n",
      "2020-07-27 16:56:57,663 INFO: deleting the raw counts dictionary of 5267 items\n",
      "2020-07-27 16:56:57,664 INFO: sample=0.001 downsamples 61 most-common words\n",
      "2020-07-27 16:56:57,666 INFO: downsampling leaves estimated 7044847 word corpus (86.3% of prior 8160401)\n",
      "2020-07-27 16:56:57,690 INFO: estimated required memory for 4334 words and 100 dimensions: 5634200 bytes\n",
      "2020-07-27 16:56:57,693 INFO: resetting layer weights\n",
      "2020-07-27 16:56:58,919 INFO: training model with 8 workers on 4334 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-07-27 16:56:59,938 INFO: EPOCH 1 - PROGRESS: at 13.33% examples, 956052 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:00,943 INFO: EPOCH 1 - PROGRESS: at 27.48% examples, 983248 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:01,943 INFO: EPOCH 1 - PROGRESS: at 41.58% examples, 963521 words/s, in_qsize 16, out_qsize 2\n",
      "2020-07-27 16:57:02,950 INFO: EPOCH 1 - PROGRESS: at 55.69% examples, 978435 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-27 16:57:03,975 INFO: EPOCH 1 - PROGRESS: at 69.60% examples, 971116 words/s, in_qsize 13, out_qsize 2\n",
      "2020-07-27 16:57:04,976 INFO: EPOCH 1 - PROGRESS: at 83.63% examples, 973893 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:05,979 INFO: EPOCH 1 - PROGRESS: at 97.98% examples, 973811 words/s, in_qsize 15, out_qsize 1\n",
      "2020-07-27 16:57:06,057 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-27 16:57:06,075 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-27 16:57:06,091 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-27 16:57:06,101 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-27 16:57:06,114 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-27 16:57:06,118 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-27 16:57:06,129 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-27 16:57:06,133 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-27 16:57:06,134 INFO: EPOCH - 1 : training on 8162291 raw words (7008724 effective words) took 7.2s, 972154 effective words/s\n",
      "2020-07-27 16:57:07,151 INFO: EPOCH 2 - PROGRESS: at 13.12% examples, 944278 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:08,153 INFO: EPOCH 2 - PROGRESS: at 26.61% examples, 947196 words/s, in_qsize 16, out_qsize 1\n",
      "2020-07-27 16:57:09,164 INFO: EPOCH 2 - PROGRESS: at 41.71% examples, 968662 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:10,205 INFO: EPOCH 2 - PROGRESS: at 55.99% examples, 975643 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-27 16:57:11,214 INFO: EPOCH 2 - PROGRESS: at 70.69% examples, 981004 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:12,226 INFO: EPOCH 2 - PROGRESS: at 84.73% examples, 981105 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:13,235 INFO: EPOCH 2 - PROGRESS: at 98.77% examples, 975171 words/s, in_qsize 12, out_qsize 0\n",
      "2020-07-27 16:57:13,273 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-27 16:57:13,285 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-27 16:57:13,289 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-27 16:57:13,298 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-27 16:57:13,316 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-27 16:57:13,325 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-27 16:57:13,330 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-27 16:57:13,333 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-27 16:57:13,334 INFO: EPOCH - 2 : training on 8162291 raw words (7007133 effective words) took 7.2s, 974382 effective words/s\n",
      "2020-07-27 16:57:14,380 INFO: EPOCH 3 - PROGRESS: at 13.12% examples, 925273 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:15,402 INFO: EPOCH 3 - PROGRESS: at 27.03% examples, 949210 words/s, in_qsize 13, out_qsize 2\n",
      "2020-07-27 16:57:16,412 INFO: EPOCH 3 - PROGRESS: at 40.76% examples, 935148 words/s, in_qsize 16, out_qsize 1\n",
      "2020-07-27 16:57:17,416 INFO: EPOCH 3 - PROGRESS: at 53.39% examples, 924637 words/s, in_qsize 13, out_qsize 2\n",
      "2020-07-27 16:57:18,418 INFO: EPOCH 3 - PROGRESS: at 66.90% examples, 929357 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:19,465 INFO: EPOCH 3 - PROGRESS: at 79.16% examples, 910409 words/s, in_qsize 16, out_qsize 1\n",
      "2020-07-27 16:57:20,465 INFO: EPOCH 3 - PROGRESS: at 91.79% examples, 906380 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:21,015 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-27 16:57:21,021 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-27 16:57:21,035 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-27 16:57:21,056 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-27 16:57:21,063 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-27 16:57:21,064 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-27 16:57:21,073 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-27 16:57:21,078 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-27 16:57:21,079 INFO: EPOCH - 3 : training on 8162291 raw words (7009082 effective words) took 7.7s, 906932 effective words/s\n",
      "2020-07-27 16:57:22,107 INFO: EPOCH 4 - PROGRESS: at 12.57% examples, 903804 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:23,120 INFO: EPOCH 4 - PROGRESS: at 26.63% examples, 939279 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:24,121 INFO: EPOCH 4 - PROGRESS: at 39.24% examples, 909396 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:25,126 INFO: EPOCH 4 - PROGRESS: at 53.40% examples, 933047 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:26,143 INFO: EPOCH 4 - PROGRESS: at 65.77% examples, 917318 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:27,145 INFO: EPOCH 4 - PROGRESS: at 78.08% examples, 908836 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-27 16:57:28,148 INFO: EPOCH 4 - PROGRESS: at 89.98% examples, 896624 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:28,785 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-27 16:57:28,788 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-27 16:57:28,792 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-27 16:57:28,807 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-27 16:57:28,818 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-27 16:57:28,822 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-27 16:57:28,839 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-27 16:57:28,844 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-27 16:57:28,846 INFO: EPOCH - 4 : training on 8162291 raw words (7008366 effective words) took 7.8s, 903638 effective words/s\n",
      "2020-07-27 16:57:29,856 INFO: EPOCH 5 - PROGRESS: at 12.90% examples, 934789 words/s, in_qsize 15, out_qsize 0\n",
      "2020-07-27 16:57:30,862 INFO: EPOCH 5 - PROGRESS: at 25.10% examples, 891971 words/s, in_qsize 13, out_qsize 2\n",
      "2020-07-27 16:57:31,866 INFO: EPOCH 5 - PROGRESS: at 38.19% examples, 890390 words/s, in_qsize 13, out_qsize 2\n",
      "2020-07-27 16:57:32,868 INFO: EPOCH 5 - PROGRESS: at 52.17% examples, 914609 words/s, in_qsize 14, out_qsize 1\n",
      "2020-07-27 16:57:33,875 INFO: EPOCH 5 - PROGRESS: at 65.66% examples, 920331 words/s, in_qsize 16, out_qsize 4\n",
      "2020-07-27 16:57:34,880 INFO: EPOCH 5 - PROGRESS: at 79.23% examples, 925168 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-27 16:57:35,915 INFO: EPOCH 5 - PROGRESS: at 91.04% examples, 905856 words/s, in_qsize 16, out_qsize 0\n",
      "2020-07-27 16:57:36,560 INFO: worker thread finished; awaiting finish of 7 more threads\n",
      "2020-07-27 16:57:36,570 INFO: worker thread finished; awaiting finish of 6 more threads\n",
      "2020-07-27 16:57:36,571 INFO: worker thread finished; awaiting finish of 5 more threads\n",
      "2020-07-27 16:57:36,578 INFO: worker thread finished; awaiting finish of 4 more threads\n",
      "2020-07-27 16:57:36,598 INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "2020-07-27 16:57:36,608 INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "2020-07-27 16:57:36,620 INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "2020-07-27 16:57:36,634 INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "2020-07-27 16:57:36,635 INFO: EPOCH - 5 : training on 8162291 raw words (7008674 effective words) took 7.8s, 900692 effective words/s\n",
      "2020-07-27 16:57:36,638 INFO: training on a 40811455 raw words (35041979 effective words) took 37.7s, 929026 effective words/s\n",
      "2020-07-27 16:57:36,644 INFO: precomputing L2-norms of word weight vectors\n",
      "2020-07-27 16:57:36,650 INFO: saving Word2Vec object under ./word2vec.bin, separately None\n",
      "2020-07-27 16:57:36,654 INFO: not storing attribute vectors_norm\n",
      "2020-07-27 16:57:36,656 INFO: not storing attribute cum_table\n",
      "2020-07-27 16:57:36,711 INFO: saved ./word2vec.bin\n"
     ]
    }
   ],
   "source": [
    "logging.info('Start training...')\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "num_features = 100     # Word vector dimensionality\n",
    "num_workers = 8       # Number of threads to run in parallel\n",
    "\n",
    "train_texts = list(map(lambda x: list(x.split()), train_texts))\n",
    "model = Word2Vec(train_texts, workers=num_workers, size=num_features)\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# save model\n",
    "model.save(\"./word2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-27 16:58:13,179 INFO: loading Word2Vec object from ./word2vec.bin\n",
      "2020-07-27 16:58:13,299 INFO: loading wv recursively from ./word2vec.bin.wv.* with mmap=None\n",
      "2020-07-27 16:58:13,300 INFO: setting ignored attribute vectors_norm to None\n",
      "2020-07-27 16:58:13,301 INFO: loading vocabulary recursively from ./word2vec.bin.vocabulary.* with mmap=None\n",
      "2020-07-27 16:58:13,302 INFO: loading trainables recursively from ./word2vec.bin.trainables.* with mmap=None\n",
      "2020-07-27 16:58:13,303 INFO: setting ignored attribute cum_table to None\n",
      "2020-07-27 16:58:13,304 INFO: loaded ./word2vec.bin\n",
      "2020-07-27 16:58:13,323 INFO: storing 4334x100 projection weights into ./word2vec.txt\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = Word2Vec.load(\"./word2vec.bin\")\n",
    "\n",
    "# convert format\n",
    "model.wv.save_word2vec_format('./word2vec.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取测试集数据\n",
    "test_df = pd.read_csv('../input/test_a.csv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
